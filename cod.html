<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Codes Used - Data Showdown</title>
    <style>
        /* Reset default margin and padding */
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        /* Body styles */
        body {
            font-family: Arial, sans-serif;
            background-color: #f0f0f0;
            color: #333;
            line-height: 1.6;
            margin: 0;
            padding: 0;
        }

        /* Container styles */
        .container {
            display: flex;
        }

        /* Navigation styles */
        nav {
            background-color: #333;
            color: #fff;
            width: 200px; /* Width of the navigation */
            padding: 20px;
        }

        nav ul {
            list-style-type: none;
            padding: 0;
            margin: 0;
        }

        nav ul li {
            margin-bottom: 10px;
        }

        nav ul li a {
            color: #fff;
            text-decoration: none;
            display: block;
            padding: 8px;
            border-radius: 4px;
        }

        nav ul li a:hover {
            background-color: #555;
        }

        /* Main content styles */
        .main-content {
            padding: 20px;
        }

        header {
            background-color: #8ED1E9; 
            color: #fff;
            text-align: center;
            padding: 20px 0;
            margin-bottom: 20px;
        }

        /* Results specific styles */
        .result {
            margin-bottom: 20px;
        }

        .result h3 {
            margin-bottom: 10px;
        }

        .result p {
            margin-bottom: 10px;
        }

        .popup-btn {
            background-color: #007bff;
            color: #fff;
            border: none;
            padding: 8px 16px;
            cursor: pointer;
            border-radius: 4px;
            margin-right: 10px;
        }

        .popup-btn:hover {
            background-color: #0056b3;
        }

        .popup {
            display: none;
            position: fixed;
            left: 50%;
            top: 50%;
            transform: translate(-50%, -50%);
            background-color: #f9f9f9;
            border: 1px solid #ccc;
            padding: 20px;
            z-index: 9999;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
            max-width: 80%;
            max-height: 80%;
            overflow: auto;
        }

        .popup-content {
            max-height: 100%;
        }

        .close-btn {
            background-color: #dc3545;
            color: #fff;
            border: none;
            padding: 8px 16px;
            cursor: pointer;
            border-radius: 4px;
            margin-top: 10px;
        }

        .close-btn:hover {
            background-color: #bd2130;
        }
    </style>
</head>

<body>
    <header>
        <h1>Comparing machine learning performance on Big Query(SQL), Azure and Python</h1>
    </header>
    <div class="container">
        <nav>
            <ul>
                <li><a href="index.html">Intro</a></li>
                <li><a href="des.html">Tools Used</a></li>
                <li><a href="meth.html">Method</a></li>
                <li><a href="res.html">Result</a></li>
                <li><a href="cod.html">Codes</a></li>
                <li><a href="con.html">Conclusion</a></li>
                <li><a href="about.html">Contributors</a></li>
            </ul>
        </nav>
        <div class="main-content">
            <h2>Codes Used</h2>
            <ol>
                <strong>Big Query(SQL):</strong>
                <li>Linear Regression</li>
                <pre><code>
            CREATE OR REPLACE MODEL `realstate-data.Data_Set.Housing_Model`
            OPTIONS(model_type='linear_reg', input_label_cols=['price']) AS
            SELECT
              area,
              bedrooms,
              bathrooms,
              stories,
              mainroad,
              guestroom,
              basement,
              hotwaterheating,
              airconditioning,
              parking,
              prefarea,
              furnishingstatus,
              price
            FROM
              `realstate-data.Data_Set.Housing`;
              
            -- Evaluate the model
            SELECT
              *
            FROM
              ML.EVALUATE(MODEL `realstate-data.Data_Set.Housing_Model`,
              (
                SELECT
                  area,
                  bedrooms,
                  bathrooms,
                  stories,
                  mainroad,
                  guestroom,
                  basement,
                  hotwaterheating,
                  airconditioning,
                  parking,
                  prefarea,
                  furnishingstatus,
                  price
                FROM
                  `realstate-data.Data_Set.Housing`
              ));
                </code></pre>
                <li>XGBoost</li>
                <pre><code>
            -- Create and train XGBoost model
            CREATE OR REPLACE MODEL `realstate-data.Data_Set.XGBoost_Model`
            OPTIONS(model_type='BOOSTED_TREE_REGRESSOR',
                    BOOSTER_TYPE='GBTREE',
                    NUM_PARALLEL_TREE=1,  -- Number of parallel trees
                    MAX_ITERATIONS=100,   -- Number of boosting iterations
                    EARLY_STOP=TRUE,      -- Enable early stopping 
                    INPUT_LABEL_COLS=['price'])  -- Specify the label column
            AS
            SELECT
              area,
              bedrooms,
              bathrooms,
              stories,
              mainroad,
              guestroom,
              basement,
              hotwaterheating,
              airconditioning,
              parking,
              prefarea,
              CASE WHEN furnishingstatus = 'furnished' THEN 1 ELSE 0 END AS furnished,
              price
            FROM
              `realstate-data.Data_Set.Housing`;
              
            -- Evaluate the XGBoost model
            SELECT
              *
            FROM
              ML.EVALUATE(MODEL `realstate-data.Data_Set.XGBoost_Model`,
              (
                SELECT
                  area,
                  bedrooms,
                  bathrooms,
                  stories,
                  mainroad,
                  guestroom,
                  basement,
                  hotwaterheating,
                  airconditioning,
                  parking,
                  prefarea,
                  CASE WHEN furnishingstatus = 'furnished' THEN 1 ELSE 0 END AS furnished,
                  price
                FROM
                  `realstate-data.Data_Set.Housing`
              ));
                </code></pre>
            </ol>

            <ol>
                <strong>Azure Machine learning Studio</strong>
                <li>Linear Regression</li>
                <img src="azure_linearregression_model.png" alt="az_Lin_model">
                <li>Linear Regression</li>
                <img src="azure_lighBGM_model.png" alt="az_lig_model">
            </ol>

            
            <ol>
                <strong>Python:</strong>
                <li>Linear Regression</li>
                <pre><code>
            import numpy as np
            import pandas as pd
            from sklearn.model_selection import train_test_split
            from sklearn.preprocessing import OneHotEncoder
            from sklearn.linear_model import LinearRegression
            from sklearn.metrics import mean_squared_error, r2_score

            df = bf.read_gbq("rent-prediction-420015.rentpred.rent")
            df=df.to_pandas()

            encoder=OneHotEncoder(sparse=False,drop='first')
            categorical_cols=['guestroom','basement','mainroad','hotwaterheating','airconditioning','furnishingstatus','prefarea']
            encoded_categorical=encoder.fit_transform(df[categorical_cols])

            encoded_df=pd.DataFrame(encoded_categorical,columns=encoder.get_feature_names_out(categorical_cols))

            preprocessed_data=df.drop(categorical_cols,axis=1)
            preprocessed_data=pd.concat([preprocessed_data,encoded_df],axis=1)




            df['price_log'] = np.log(df['price'] + 1)


            X=preprocessed_data[['area','guestroom_1.0', 'basement_1.0' , 'prefarea_1.0' ,'bedrooms','bathrooms','parking','mainroad_1.0','hotwaterheating_1.0','airconditioning_1.0','furnishingstatus_semi-furnished','furnishingstatus_unfurnished']]
            y=df['price_log']


            X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)
            X_train.shape,X_test.shape


            from sklearn.metrics import mean_squared_error
            import numpy as np



            model = LinearRegression()
            model.fit(X_train, y_train)

            predictions = model.predict(X_test)

            mse = mean_squared_error(y_test, predictions)
            r2 = r2_score(y_test, predictions)

            # Print evaluation metrics
            print(f'Mean Squared Error: {mse}')
            print(f'R^2 score: {r2}')


            residuals = y_test - predictions

            import matplotlib.pyplot as plt

            plt.figure(figsize=(10, 5))
            plt.hist(residuals, bins=20)
            plt.xlabel('Residual')
            plt.ylabel('Frequency')
            plt.title('Distribution of Residuals')
            plt.show()

            from sklearn.metrics import r2_score

            # Calculate R^2 score
            r2 = r2_score(y_test, predictions)

            print('R^2 score:', r2)
                </code></pre>
                <li>XGBoost</li>
                <pre><code>
            import bigframes.pandas as bf

            bf.options.bigquery.location = "us-east1" #this variable is set based on the dataset you chose to query
            bf.options.bigquery.project = "rent-prediction-420015" 
            df = bf.read_gbq("rent-prediction-420015.rentpred.rent")
            import numpy as np
            import pandas as pd
            from sklearn.model_selection import train_test_split
            from sklearn.preprocessing import OneHotEncoder

            df = bf.read_gbq("rent-prediction-420015.rentpred.rent")
            df=df.to_pandas()

            encoder=OneHotEncoder(sparse=False,drop='first')
            categorical_cols=['guestroom','basement','mainroad','hotwaterheating','airconditioning','furnishingstatus','prefarea']
            encoded_categorical=encoder.fit_transform(df[categorical_cols])

            encoded_df=pd.DataFrame(encoded_categorical,columns=encoder.get_feature_names_out(categorical_cols))

            preprocessed_data=df.drop(categorical_cols,axis=1)
            preprocessed_data=pd.concat([preprocessed_data,encoded_df],axis=1)



            df['price_log'] = np.log(df['price'] + 1)

            X=preprocessed_data[['area','guestroom_1.0', 'basement_1.0' , 'prefarea_1.0' ,'bedrooms','bathrooms','parking','mainroad_1.0','hotwaterheating_1.0','airconditioning_1.0','furnishingstatus_semi-furnished','furnishingstatus_unfurnished']]
            y=df['price_log']

            X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)
            X_train.shape,X_test.shape

            from xgboost import DMatrix,train
            from sklearn.metrics import mean_squared_error
            import numpy as np

            dtrain=DMatrix(X_train,label=y_train)
            dtest=DMatrix(X_test,label=y_test)

            params = {'objective':'reg:squarederror', 'learinng_rate':0.1,'max_depth': 2,'min_child_weight': 2,'subsample': 0.8,'colsample_bytree': 0.8}
            .
            eval_data= [(dtrain,'train'),(dtest,'eval')]

            model=train(params,dtrain,num_boost_round=100,evals=eval_data)

            predictions= model.predict(dtest)

            error=model.eval(dtest)

            print('Evaluation error:', error)

            residuals = y_test - predictions

            import matplotlib.pyplot as plt

            plt.figure(figsize=(10, 5))
            plt.hist(residuals, bins=20)
            plt.xlabel('Residual')
            plt.ylabel('Frequency')
            plt.title('Distribution of Residuals')
            plt.show()

            from sklearn.metrics import r2_score

            # Calculate R^2 score
            r2 = r2_score(y_test, predictions)

            print('R^2 score:', r2)


            from joblib import dump

            dump(model, 'model.joblib')
                </code></pre>
                <li>lightGBM</li>
                <pre><code>
            import lightgbm as lgb
            import numpy as np
            import pandas as pd
            from sklearn.model_selection import train_test_split
            from sklearn.preprocessing import OneHotEncoder
            import matplotlib.pyplot as plt

            df = bf.read_gbq("rent-prediction-420015.rentpred.rent")
            df=df.to_pandas()

            encoder=OneHotEncoder(sparse=False,drop='first')
            categorical_cols=['guestroom','basement','mainroad','hotwaterheating','airconditioning','furnishingstatus','prefarea']
            encoded_categorical=encoder.fit_transform(df[categorical_cols])

            encoded_df=pd.DataFrame(encoded_categorical,columns=encoder.get_feature_names_out(categorical_cols))

            preprocessed_data=df.drop(categorical_cols,axis=1)
            preprocessed_data=pd.concat([preprocessed_data,encoded_df],axis=1)




            df['price_log'] = np.log(df['price'] + 1)  


            X=preprocessed_data[['area','guestroom_1.0', 'basement_1.0' , 'prefarea_1.0' ,'bedrooms','bathrooms','parking','mainroad_1.0','hotwaterheating_1.0','airconditioning_1.0','furnishingstatus_semi-furnished','furnishingstatus_unfurnished']]
            y=df['price_log']


            X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)
            X_train.shape,X_test.shape

            from xgboost import DMatrix,train
            from sklearn.metrics import mean_squared_error
            import numpy as np

            # Assuming that df has already been loaded and preprocessed

            # Splitting the data
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

            # LightGBM dataset formatting (no need for DMatrix, as in XGBoost)
            train_data = lgb.Dataset(X_train, label=y_train)
            valid_data = lgb.Dataset(X_test, label=y_test)

            # Parameters for LightGBM
            params = {
                'objective': 'regression',
                'metric': 'rmse',
                'learning_rate': 0.1,
                'max_depth': 2,
                'num_leaves': 31,  # we need to define num_leaves when using LightGBM
                'min_data_in_leaf': 2,  # this is similar to min_child_weight in XGBoost
                'subsample': 0.8,
                'colsample_bytree': 0.8
            }

            # Training the model

            model = lgb.train(
                params,
                train_data,
                num_boost_round=100,
                valid_sets=[train_data, valid_data],
                valid_names=['train', 'valid']
                
            )

            # Making predictions
            predictions = model.predict(X_test)

            # Evaluating the model
            error = mean_squared_error(y_test, predictions)
            print('Evaluation error (MSE):', error)

            # Plot residuals
            residuals = y_test - predictions
            plt.figure(figsize=(10, 5))
            plt.hist(residuals, bins=20)
            plt.xlabel('Residual')
            plt.ylabel('Frequency')
            plt.title('Distribution of Residuals')
            plt.show()

            from sklearn.metrics import r2_score
            # R^2 score
            r2 = r2_score(y_test, predictions)
            print('R^2 score:', r2)
                </code></pre>
            </ol>

</body>

</html>
